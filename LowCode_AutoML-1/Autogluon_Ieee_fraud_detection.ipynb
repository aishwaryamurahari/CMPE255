{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Steps to use AutoGluon to become a serious Kaggle competitor without writing lots of code. This example uses IEEE fraud detection data"
      ],
      "metadata": {
        "id": "UyBGNHe-sFE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Run Bash command:*"
      ],
      "metadata": {
        "id": "0pQQgTqvr_0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLHwCZxbev0j",
        "outputId": "997728ce-9b06-4dc0-f4c3-82aa6cd62b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Creating a kaggle folder*"
      ],
      "metadata": {
        "id": "qQbHPQ9qsvfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n"
      ],
      "metadata": {
        "id": "tROG9GeafZJY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*After creating a new API from kaggle and downloading the kaggle.json file, move downloaded file to this location on machine*"
      ],
      "metadata": {
        "id": "IxE98Nivs0eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/\n"
      ],
      "metadata": {
        "id": "npkQpDqjfc7c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Granting read and write permissions to the file's owner and for maintaining the security and privacy of the credentials when using Kaggle’s API*"
      ],
      "metadata": {
        "id": "O28nfox5tDu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "i9lAtVeRfe0R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Downloads the IEEE fraud detection data*"
      ],
      "metadata": {
        "id": "IjbeilqEtxXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28LvHkbiflGu",
        "outputId": "cbaa01a1-d46a-449d-c2a3-e094a1c2dc1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ieee-fraud-detection.zip to /content\n",
            " 92% 109M/118M [00:00<00:00, 107MB/s] \n",
            "100% 118M/118M [00:00<00:00, 126MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Unzips the downloaded IEEE fraud detection folder*\n",
        "\n"
      ],
      "metadata": {
        "id": "aNsGLd3it3Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ieee-fraud-detection.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT7i6yICk9QL",
        "outputId": "5831802d-a060-4744-e403-416410956fb9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ieee-fraud-detection.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test_identity.csv       \n",
            "  inflating: test_transaction.csv    \n",
            "  inflating: train_identity.csv      \n",
            "  inflating: train_transaction.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Install the autogluon.tabular module, which is specifically designed for tabular data, including tasks like classification, regression, and time-series forecasting. It also handles data preprocessing, model training, and hyperparameter tuning automatically.*"
      ],
      "metadata": {
        "id": "ToHRhLgquWyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon.tabular"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AtGuvprJ2-rg",
        "outputId": "3ffc0d43-400a-4354-f400-4036295ca85f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon.tabular\n",
            "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (1.26.4)\n",
            "Collecting scipy<1.13,>=1.5.4 (from autogluon.tabular)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (1.3.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (3.3)\n",
            "Collecting autogluon.core==1.1.1 (from autogluon.tabular)\n",
            "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.features==1.1.1 (from autogluon.tabular)\n",
            "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading boto3-1.35.19-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular) (71.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (3.5.0)\n",
            "Collecting botocore<1.36.0,>=1.35.19 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading botocore-1.35.19-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->autogluon.tabular) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (2024.8.30)\n",
            "Downloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.19-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.19-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, jmespath, botocore, s3transfer, boto3, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.tabular-1.1.1 boto3-1.35.19 botocore-1.35.19 jmespath-1.0.1 s3transfer-0.10.2 scipy-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Loading data\n",
        "directory = '/content/'\n",
        "label = 'isFraud'\n",
        "eval_metric = 'roc_auc'\n",
        "save_path = directory + 'AutoGluonModels/'\n",
        "\n",
        "# Load data in chunks to reduce memory usage\n",
        "chunk_size = 100000\n",
        "train_identity = pd.read_csv(directory + 'train_identity.csv', chunksize=chunk_size)\n",
        "train_transaction = pd.read_csv(directory + 'train_transaction.csv', chunksize=chunk_size)\n",
        "\n",
        "# Process data in chunks\n",
        "def process_chunk(identity_chunk, transaction_chunk):\n",
        "    # Merge chunks\n",
        "    merged_chunk = pd.merge(transaction_chunk, identity_chunk, on='TransactionID', how='left')\n",
        "\n",
        "    # Impute missing values\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    imputed_chunk = imputer.fit_transform(merged_chunk.select_dtypes(include=[np.number]))\n",
        "\n",
        "    # Apply PCA\n",
        "    pca = PCA(n_components=0.95)\n",
        "    pca_chunk = pca.fit_transform(imputed_chunk)\n",
        "\n",
        "    # Convert back to DataFrame\n",
        "    processed_chunk = pd.DataFrame(pca_chunk)\n",
        "    processed_chunk['isFraud'] = merged_chunk['isFraud'].values\n",
        "\n",
        "    return processed_chunk\n",
        "\n",
        "# Process chunks and concatenate results\n",
        "processed_chunks = []\n",
        "for identity_chunk, transaction_chunk in zip(train_identity, train_transaction):\n",
        "    processed_chunk = process_chunk(identity_chunk, transaction_chunk)\n",
        "    processed_chunks.append(processed_chunk)\n",
        "\n",
        "train_data = pd.concat(processed_chunks, ignore_index=True)\n",
        "\n",
        "# Data sampling (10% of the data for experimentation)\n",
        "train_data = train_data.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# AutoGluon settings for less resource-intensive training\n",
        "predictor = TabularPredictor(label='isFraud', eval_metric=eval_metric, path=save_path, verbosity=3)\n",
        "predictor.fit(\n",
        "    train_data,\n",
        "    presets='medium_quality',\n",
        "    time_limit=1800,  # Reduced time limit\n",
        "    ag_args_fit={'num_bag_folds': 2, 'num_stack_levels': 0},\n",
        "    num_bag_sets=1,\n",
        "    keep_only_best=True,\n",
        "    refit_full=False,\n",
        "    set_best_to_refit_full=False\n",
        ")\n",
        "\n",
        "# Print summary of fit results\n",
        "results = predictor.fit_summary()\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M8PCdKm87Wfx",
        "outputId": "5cfc0849-40bd-48ef-850b-45f0bf6eddc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:558: UserWarning: Skipping features without any observed values: ['id_01' 'id_02' 'id_03' 'id_04' 'id_05' 'id_06' 'id_07' 'id_08' 'id_09'\n",
            " 'id_10' 'id_11' 'id_13' 'id_14' 'id_17' 'id_18' 'id_19' 'id_20' 'id_21'\n",
            " 'id_22' 'id_24' 'id_25' 'id_26' 'id_32']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "GPU Count:          0\n",
            "Memory Avail:       9.81 GB / 12.67 GB (77.4%)\n",
            "Disk Space Avail:   73.28 GB / 107.72 GB (68.0%)\n",
            "===================================================\n",
            "Presets specified: ['medium_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0},\n",
            " 'auto_stack': False,\n",
            " 'keep_only_best': True,\n",
            " 'num_bag_sets': 1,\n",
            " 'refit_full': False,\n",
            " 'set_best_to_refit_full': False}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0},\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': True,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': 1,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 1800s\n",
            "AutoGluon will save models to \"/content/AutoGluonModels/\"\n",
            "Train Data Rows:    20000\n",
            "Train Data Columns: 2\n",
            "Label Column:       isFraud\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [0, 1]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9977.43 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 2 | ['0', '1']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 2 | ['0', '1']\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 2 | ['0', '1']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['0', '1']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 2 | ['0', '1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['0', '1']\n",
            "\t0.2s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.31 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.28s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 18000, Val Rows: 2000\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Saving /content/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/X_val.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tKNeighborsUnif: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tKNeighborsDist: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBMXT: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}}\n",
            "\tLightGBM: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}}\n",
            "\tRandomForestGini: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}}\n",
            "\tExtraTreesGini: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}}\n",
            "\tXGBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}}\n",
            "\tNeuralNetTorch: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}}\n",
            "\tLightGBMLarge: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_bag_folds': 2, 'num_stack_levels': 0}}\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ... Training model for up to 1799.72s of the 1799.68s of remaining time.\n",
            "\tFitting KNeighborsUnif with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/18000 rows) (1799.69s remaining time)\n",
            "\t0.01s \t= Train Time (Using 18000/18000 rows) (1799.68s remaining time)\n",
            "Saving /content/AutoGluonModels/models/KNeighborsUnif/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/KNeighborsUnif/y_pred_proba_val.pkl\n",
            "\t0.543\t = Validation score   (roc_auc)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t102493.8\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: KNeighborsDist ... Training model for up to 1799.62s of the 1799.58s of remaining time.\n",
            "\tFitting KNeighborsDist with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/18000 rows) (1799.6s remaining time)\n",
            "\t0.02s \t= Train Time (Using 18000/18000 rows) (1799.59s remaining time)\n",
            "Saving /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/KNeighborsDist/y_pred_proba_val.pkl\n",
            "\t0.5484\t = Validation score   (roc_auc)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t127538.8\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBMXT ... Training model for up to 1799.54s of the 1799.5s of remaining time.\n",
            "\tFitting LightGBMXT with 'num_gpus': 0, 'num_cpus': 1\n",
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.130373\n",
            "[100]\tvalid_set's binary_logloss: 0.129903\n",
            "[150]\tvalid_set's binary_logloss: 0.129056\n",
            "[200]\tvalid_set's binary_logloss: 0.1288\n",
            "[250]\tvalid_set's binary_logloss: 0.128521\n",
            "[300]\tvalid_set's binary_logloss: 0.128334\n",
            "[350]\tvalid_set's binary_logloss: 0.128343\n",
            "[400]\tvalid_set's binary_logloss: 0.128134\n",
            "[450]\tvalid_set's binary_logloss: 0.127927\n",
            "[500]\tvalid_set's binary_logloss: 0.127828\n",
            "[550]\tvalid_set's binary_logloss: 0.127748\n",
            "[600]\tvalid_set's binary_logloss: 0.127802\n",
            "[650]\tvalid_set's binary_logloss: 0.127747\n",
            "[700]\tvalid_set's binary_logloss: 0.12776\n",
            "[750]\tvalid_set's binary_logloss: 0.12801\n",
            "[800]\tvalid_set's binary_logloss: 0.128024\n",
            "[850]\tvalid_set's binary_logloss: 0.12814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "\t0.6391\t = Validation score   (roc_auc)\n",
            "\t3.18s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "\t18705.3\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM ... Training model for up to 1796.18s of the 1796.14s of remaining time.\n",
            "\tFitting LightGBM with 'num_gpus': 0, 'num_cpus': 1\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.128812\n",
            "[100]\tvalid_set's binary_logloss: 0.131344\n",
            "[150]\tvalid_set's binary_logloss: 0.134381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "\t0.6172\t = Validation score   (roc_auc)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t1258228.3\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini ... Training model for up to 1795.61s of the 1795.58s of remaining time.\n",
            "\tFitting RandomForestGini with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "\t0.5645\t = Validation score   (roc_auc)\n",
            "\t14.0s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "\t12739.3\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr ... Training model for up to 1781.39s of the 1781.36s of remaining time.\n",
            "\tFitting RandomForestEntr with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "\t0.563\t = Validation score   (roc_auc)\n",
            "\t16.97s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "\t13543.9\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: CatBoost ... Training model for up to 1764.21s of the 1764.17s of remaining time.\n",
            "\tFitting CatBoost with 'num_gpus': 0, 'num_cpus': 1\n",
            "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
            "\t\t\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/common/utils/try_import.py\", line 63, in try_import_catboost\n",
            "    import catboost\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 95, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/common/utils/try_import.py\", line 70, in try_import_catboost\n",
            "    raise ImportError()\n",
            "ImportError\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 1763.99s of the 1763.96s of remaining time.\n",
            "\tFitting ExtraTreesGini with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "\t0.5651\t = Validation score   (roc_auc)\n",
            "\t2.18s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "\t12754.1\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 1761.45s of the 1761.42s of remaining time.\n",
            "\tFitting ExtraTreesEntr with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "\t0.5757\t = Validation score   (roc_auc)\n",
            "\t2.3s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "\t12774.9\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 1758.77s of the 1758.73s of remaining time.\n",
            "\tFitting NeuralNetFastAI with 'num_gpus': 0, 'num_cpus': 1\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 0/0 categorical features\n",
            "Using 2 cont features\n",
            "Automated batch size selection: 256\n",
            "TabularModel(\n",
            "  (embeds): ModuleList()\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): LinBnDrop(\n",
            "      (0): Linear(in_features=2, out_features=200, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): LinBnDrop(\n",
            "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): LinBnDrop(\n",
            "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Automated epochs selection: training for 30 epoch(s). Estimated time budget use 22.70 / 1758.61 sec\n",
            "Better model found at epoch 0 with valid_loss value: 0.5343976616859436.\n",
            "Better model found at epoch 1 with valid_loss value: 0.19772152602672577.\n",
            "Better model found at epoch 2 with valid_loss value: 0.12963372468948364.\n",
            "Better model found at epoch 15 with valid_loss value: 0.12858085334300995.\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
            "Model validation metrics: 0.12858085334300995\n",
            "Saving /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Saving /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "\t0.6019\t = Validation score   (roc_auc)\n",
            "\t27.72s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "\t24643.3\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: XGBoost ... Training model for up to 1730.88s of the 1730.84s of remaining time.\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.18719\n",
            "[50]\tvalidation_0-logloss:0.12895\n",
            "[100]\tvalidation_0-logloss:0.12999\n",
            "[150]\tvalidation_0-logloss:0.13101\n",
            "[200]\tvalidation_0-logloss:0.13241\n",
            "[224]\tvalidation_0-logloss:0.13269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "\t0.6088\t = Validation score   (roc_auc)\n",
            "\t1.29s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t127857.6\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 1729.54s of the 1729.51s of remaining time.\n",
            "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 1\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"0\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"1\"\n",
            "    ],\n",
            "    \"onehot\": [],\n",
            "    \"embed\": [],\n",
            "    \"language\": [],\n",
            "    \"bool\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 18000 examples, 2 features (2 vector, 0 embedding)\n",
            "Training on CPU\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.1, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 500 epochs...\n",
            "Epoch 1 (Update 140).\tTrain loss: 0.2204, Val roc_auc: 0.5625, Best Epoch: 1\n",
            "Epoch 2 (Update 280).\tTrain loss: 0.1335, Val roc_auc: 0.5626, Best Epoch: 2\n",
            "Epoch 3 (Update 420).\tTrain loss: 0.1318, Val roc_auc: 0.5722, Best Epoch: 3\n",
            "Epoch 4 (Update 560).\tTrain loss: 0.1311, Val roc_auc: 0.5845, Best Epoch: 4\n",
            "Epoch 5 (Update 700).\tTrain loss: 0.131, Val roc_auc: 0.565, Best Epoch: 4\n",
            "Epoch 6 (Update 840).\tTrain loss: 0.1314, Val roc_auc: 0.575, Best Epoch: 4\n",
            "Epoch 7 (Update 980).\tTrain loss: 0.1316, Val roc_auc: 0.5699, Best Epoch: 4\n",
            "Epoch 8 (Update 1120).\tTrain loss: 0.1303, Val roc_auc: 0.5515, Best Epoch: 4\n",
            "Epoch 9 (Update 1260).\tTrain loss: 0.1315, Val roc_auc: 0.5625, Best Epoch: 4\n",
            "Epoch 10 (Update 1400).\tTrain loss: 0.1304, Val roc_auc: 0.5597, Best Epoch: 4\n",
            "Epoch 11 (Update 1540).\tTrain loss: 0.1305, Val roc_auc: 0.5474, Best Epoch: 4\n",
            "Epoch 12 (Update 1680).\tTrain loss: 0.1304, Val roc_auc: 0.5536, Best Epoch: 4\n",
            "Epoch 13 (Update 1820).\tTrain loss: 0.1309, Val roc_auc: 0.5607, Best Epoch: 4\n",
            "Epoch 14 (Update 1960).\tTrain loss: 0.1307, Val roc_auc: 0.572, Best Epoch: 4\n",
            "Epoch 15 (Update 2100).\tTrain loss: 0.1314, Val roc_auc: 0.5462, Best Epoch: 4\n",
            "Epoch 16 (Update 2240).\tTrain loss: 0.1315, Val roc_auc: 0.5646, Best Epoch: 4\n",
            "Epoch 17 (Update 2380).\tTrain loss: 0.1298, Val roc_auc: 0.5682, Best Epoch: 4\n",
            "Epoch 18 (Update 2520).\tTrain loss: 0.1305, Val roc_auc: 0.5332, Best Epoch: 4\n",
            "Epoch 19 (Update 2660).\tTrain loss: 0.1314, Val roc_auc: 0.5639, Best Epoch: 4\n",
            "Epoch 20 (Update 2800).\tTrain loss: 0.1303, Val roc_auc: 0.5335, Best Epoch: 4\n",
            "Epoch 21 (Update 2940).\tTrain loss: 0.1303, Val roc_auc: 0.5563, Best Epoch: 4\n",
            "Epoch 22 (Update 3080).\tTrain loss: 0.1307, Val roc_auc: 0.5767, Best Epoch: 4\n",
            "Epoch 23 (Update 3220).\tTrain loss: 0.1311, Val roc_auc: 0.5758, Best Epoch: 4\n",
            "Epoch 24 (Update 3360).\tTrain loss: 0.1306, Val roc_auc: 0.5763, Best Epoch: 4\n",
            "Best model found on Epoch 4 (Update 560). Val roc_auc: 0.5845111687204801\n",
            "/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model = torch.load(net_filename)\n",
            "Saving /content/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "\t0.5845\t = Validation score   (roc_auc)\n",
            "\t17.1s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "\t78005.3\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBMLarge ... Training model for up to 1712.39s of the 1712.35s of remaining time.\n",
            "\tFitting LightGBMLarge with 'num_gpus': 0, 'num_cpus': 1\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.134198\n",
            "[100]\tvalid_set's binary_logloss: 0.140116\n",
            "[150]\tvalid_set's binary_logloss: 0.146112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Saving /content/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "\t0.6036\t = Validation score   (roc_auc)\n",
            "\t1.45s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t362719.2\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/KNeighborsUnif/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "Loading: /content/AutoGluonModels/utils/attr/KNeighborsDist/y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1710.84s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 22\n",
            "Ensemble weights: \n",
            "[0.         0.04545455 0.13636364 0.         0.         0.\n",
            " 0.13636364 0.         0.68181818 0.         0.         0.        ]\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.682, 'LightGBMXT': 0.136, 'ExtraTreesGini': 0.136, 'KNeighborsDist': 0.045}\n",
            "\t0.6917\t = Validation score   (roc_auc)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t5520.1\t = Inference  throughput (rows/s | 2000 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 89.55s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5520.1 rows/s (2000 batch size)\n",
            "Loading: /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsUnif/model.pkl\n",
            "Deleting model KNeighborsUnif. All files under /content/AutoGluonModels/models/KNeighborsUnif will be removed.\n",
            "Loading: /content/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Deleting model LightGBM. All files under /content/AutoGluonModels/models/LightGBM will be removed.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Deleting model RandomForestGini. All files under /content/AutoGluonModels/models/RandomForestGini will be removed.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Deleting model RandomForestEntr. All files under /content/AutoGluonModels/models/RandomForestEntr will be removed.\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Deleting model ExtraTreesEntr. All files under /content/AutoGluonModels/models/ExtraTreesEntr will be removed.\n",
            "Loading: /content/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Deleting model XGBoost. All files under /content/AutoGluonModels/models/XGBoost will be removed.\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "/usr/local/lib/python3.10/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(io.BytesIO(b))\n",
            "Deleting model NeuralNetTorch. All files under /content/AutoGluonModels/models/NeuralNetTorch will be removed.\n",
            "Loading: /content/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Deleting model LightGBMLarge. All files under /content/AutoGluonModels/models/LightGBMLarge will be removed.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Saving /content/AutoGluonModels/version.txt with contents \"1.1.1\"\n",
            "Saving /content/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels/\")\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L2   0.691671     roc_auc       0.362314  33.405865                0.001741           0.272109            2       True          5\n",
            "1           LightGBMXT   0.639147     roc_auc       0.106921   3.183570                0.106921           3.183570            1       True          2\n",
            "2      NeuralNetFastAI   0.601886     roc_auc       0.081158  27.722270                0.081158          27.722270            1       True          4\n",
            "3       ExtraTreesGini   0.565143     roc_auc       0.156813   2.178463                0.156813           2.178463            1       True          3\n",
            "4       KNeighborsDist   0.548430     roc_auc       0.015682   0.049454                0.015682           0.049454            1       True          1\n",
            "Number of models trained: 5\n",
            "Types of models trained:\n",
            "{'LGBModel', 'XTModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel', 'KNNModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', []) : 2 | ['0', '1']\n",
            "Plot summary of models saved to file: /content/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n",
            "{'model_types': {'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'ExtraTreesGini': 'XTModel', 'NeuralNetFastAI': 'NNFastAiTabularModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsDist': 0.5484303419865763, 'LightGBMXT': 0.6391473418800384, 'ExtraTreesGini': 0.5651434710039419, 'NeuralNetFastAI': 0.6018857203735928, 'WeightedEnsemble_L2': 0.69167051386768}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsDist': ['KNeighborsDist'], 'LightGBMXT': ['LightGBMXT'], 'ExtraTreesGini': ['ExtraTreesGini'], 'NeuralNetFastAI': ['NeuralNetFastAI'], 'WeightedEnsemble_L2': ['WeightedEnsemble_L2']}, 'model_fit_times': {'KNeighborsDist': 0.0494542121887207, 'LightGBMXT': 3.18356990814209, 'ExtraTreesGini': 2.1784629821777344, 'NeuralNetFastAI': 27.722269535064697, 'WeightedEnsemble_L2': 0.2721085548400879}, 'model_pred_times': {'KNeighborsDist': 0.01568150520324707, 'LightGBMXT': 0.10692143440246582, 'ExtraTreesGini': 0.1568126678466797, 'NeuralNetFastAI': 0.08115792274475098, 'WeightedEnsemble_L2': 0.0017409324645996094}, 'num_bag_folds': 0, 'max_stack_level': 2, 'num_classes': 2, 'model_hyperparams': {'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'ExtraTreesGini': {'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'gini'}, 'NeuralNetFastAI': {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                  model  score_val eval_metric  pred_time_val   fit_time  \\\n",
            "0  WeightedEnsemble_L2   0.691671     roc_auc       0.362314  33.405865   \n",
            "1           LightGBMXT   0.639147     roc_auc       0.106921   3.183570   \n",
            "2      NeuralNetFastAI   0.601886     roc_auc       0.081158  27.722270   \n",
            "3       ExtraTreesGini   0.565143     roc_auc       0.156813   2.178463   \n",
            "4       KNeighborsDist   0.548430     roc_auc       0.015682   0.049454   \n",
            "\n",
            "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
            "0                0.001741           0.272109            2       True   \n",
            "1                0.106921           3.183570            1       True   \n",
            "2                0.081158          27.722270            1       True   \n",
            "3                0.156813           2.178463            1       True   \n",
            "4                0.015682           0.049454            1       True   \n",
            "\n",
            "   fit_order  \n",
            "0          5  \n",
            "1          2  \n",
            "2          4  \n",
            "3          3  \n",
            "4          1  }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We ask AutoGluon for predicted class probabilities*"
      ],
      "metadata": {
        "id": "pdTVux-F-mfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "import gc\n",
        "\n",
        "# Load data in chunks to reduce memory usage\n",
        "chunk_size = 100000\n",
        "directory = '/content/'\n",
        "\n",
        "# Function to process chunks\n",
        "def process_chunks(identity_chunks, transaction_chunks):\n",
        "    processed_data = []\n",
        "    for identity_chunk, transaction_chunk in zip(identity_chunks, transaction_chunks):\n",
        "        # Merge the chunks\n",
        "        merged_chunk = pd.merge(transaction_chunk, identity_chunk, on='TransactionID', how='left')\n",
        "        processed_data.append(merged_chunk)\n",
        "\n",
        "        # Free up memory\n",
        "        del identity_chunk, transaction_chunk\n",
        "        gc.collect()\n",
        "\n",
        "    return pd.concat(processed_data, ignore_index=True)\n",
        "\n",
        "# Load and process data in chunks\n",
        "test_identity = pd.read_csv(directory + 'test_identity.csv', chunksize=chunk_size)\n",
        "test_transaction = pd.read_csv(directory + 'test_transaction.csv', chunksize=chunk_size)\n",
        "test_data = process_chunks(test_identity, test_transaction)\n",
        "\n",
        "# Optional: Sample the data if it's too large\n",
        "test_data_sample = test_data.sample(frac=0.3, random_state=42)\n",
        "\n",
        "# Downcast columns to save memory\n",
        "test_data_sample['card1'] = test_data_sample['card1'].astype('int32')\n",
        "test_data_sample['TransactionAmt'] = test_data_sample['TransactionAmt'].astype('float32')\n",
        "\n",
        "# Free up memory\n",
        "del test_data\n",
        "gc.collect()\n",
        "\n",
        "# Load the trained model\n",
        "predictor = TabularPredictor.load('/content/AutoGluonModels/')\n",
        "\n",
        "# Check the required columns in the model\n",
        "required_columns = predictor.feature_metadata.get_features()\n",
        "print(\"Required columns:\", required_columns)\n",
        "\n",
        "# Check if the test data contains all the required columns\n",
        "missing_columns = [col for col in required_columns if col not in test_data_sample.columns]\n",
        "print(\"Missing columns:\", missing_columns)\n",
        "\n",
        "# Ensure test data matches the model's required columns\n",
        "for col in missing_columns:\n",
        "    test_data_sample[col] = 0  # Fill missing columns with a default value (e.g., 0)\n",
        "\n",
        "# Predict in chunks to avoid memory overload\n",
        "chunk_size = 10000\n",
        "y_predproba = []\n",
        "\n",
        "for i in range(0, len(test_data_sample), chunk_size):\n",
        "    chunk = test_data_sample.iloc[i:i + chunk_size]\n",
        "    y_pred_chunk = predictor.predict_proba(chunk)\n",
        "    y_predproba.append(y_pred_chunk)\n",
        "\n",
        "# Concatenate predictions\n",
        "y_predproba = pd.concat(y_predproba)\n",
        "\n",
        "# Display some predictions\n",
        "print(y_predproba.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b7IDbdZPBMJw",
        "outputId": "a949062a-8fcb-4c53-a98e-7430ea09181d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/predictor.pkl\n",
            "Loading: /content/AutoGluonModels/learner.pkl\n",
            "Loading: /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required columns: ['0', '1']\n",
            "Missing columns: ['0', '1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               0         1\n",
            "119737  0.977992  0.022008\n",
            "72272   0.977992  0.022008\n",
            "158154  0.977992  0.022008\n",
            "65426   0.977992  0.022008\n",
            "30074   0.977992  0.022008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON_RRnhUSsUX",
        "outputId": "476c27b5-20b6-416f-de47-d2ccb7bb2a54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1JOiZNfSvyR",
        "outputId": "859ca865-a828-4bec-af55-ed229a42c568"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prediction probabilities for the entire test data*\n"
      ],
      "metadata": {
        "id": "tRYlQx2X-TWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data_sample, as_multiclass=False)\n"
      ],
      "metadata": {
        "id": "ZiylZxBPSzW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7355e66-4a98-4d34-f870-581514c307f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/KNeighborsDist/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "2u5vUgp5X8cO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f sample_submission.csv -m \"my first submission\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ksQrkFmZGQh",
        "outputId": "0640faa6-55c0-4520-c474-985b47ce0054"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 5.80M/5.80M [00:00<00:00, 14.3MB/s]\n",
            "Successfully submitted to IEEE-CIS Fraud Detection"
          ]
        }
      ]
    }
  ]
}